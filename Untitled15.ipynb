{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4cf883b8-8059-49f8-8a3d-bb8fa4f9c1bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 5 candidates, totalling 10 fits\n",
      "[CV] END regressor__learning_rate=0.09849549260809973, regressor__max_depth=5, regressor__n_estimators=100, regressor__subsample=0.8001557531682029; total time= 4.9min\n",
      "[CV] END regressor__learning_rate=0.09849549260809973, regressor__max_depth=5, regressor__n_estimators=100, regressor__subsample=0.8001557531682029; total time= 5.0min\n",
      "[CV] END regressor__learning_rate=0.06872700594236814, regressor__max_depth=3, regressor__n_estimators=150, regressor__subsample=0.9463987883622811; total time= 5.1min\n",
      "[CV] END regressor__learning_rate=0.06872700594236814, regressor__max_depth=3, regressor__n_estimators=150, regressor__subsample=0.9463987883622811; total time= 5.2min\n",
      "[CV] END regressor__learning_rate=0.07993292420985183, regressor__max_depth=7, regressor__n_estimators=100, regressor__subsample=0.8311989040672406; total time= 6.5min\n",
      "[CV] END regressor__learning_rate=0.07993292420985183, regressor__max_depth=7, regressor__n_estimators=100, regressor__subsample=0.8311989040672406; total time= 6.5min\n",
      "[CV] END regressor__learning_rate=0.05290418060840998, regressor__max_depth=3, regressor__n_estimators=150, regressor__subsample=0.8041168988591605; total time= 4.5min\n",
      "[CV] END regressor__learning_rate=0.09961057796456088, regressor__max_depth=3, regressor__n_estimators=100, regressor__subsample=0.9049512863264476; total time= 2.4min\n",
      "[CV] END regressor__learning_rate=0.05290418060840998, regressor__max_depth=3, regressor__n_estimators=150, regressor__subsample=0.8041168988591605; total time= 4.5min\n",
      "[CV] END regressor__learning_rate=0.09961057796456088, regressor__max_depth=3, regressor__n_estimators=100, regressor__subsample=0.9049512863264476; total time= 2.4min\n",
      "Mean Squared Error: 8.194805310470077\n",
      "R-squared: -0.0001406086630604264\n",
      "Feature Importances:\n",
      "                                   Feature  Importance\n",
      "9                  Per Capita Income (USD)    0.117827\n",
      "5             Average Treatment Cost (USD)    0.105433\n",
      "2                    Healthcare Access (%)    0.105097\n",
      "6                        Recovery Rate (%)    0.093095\n",
      "11                   Urbanization Rate (%)    0.080966\n",
      "1                       Incidence Rate (%)    0.079284\n",
      "7                                    DALYs    0.078969\n",
      "3                         Doctors per 1000    0.070693\n",
      "8               Improvement in 5 Years (%)    0.069302\n",
      "0                      Prevalence Rate (%)    0.067683\n",
      "4                   Hospital Beds per 1000    0.067682\n",
      "10                         Education Index    0.040529\n",
      "16                           Gender_Female    0.004930\n",
      "14                         Age Group_36-60    0.003040\n",
      "23   Availability of Vaccines/Treatment_No    0.002515\n",
      "22              Treatment Type_Vaccination    0.002494\n",
      "21                  Treatment Type_Therapy    0.002443\n",
      "17                             Gender_Male    0.002085\n",
      "20                  Treatment Type_Surgery    0.001672\n",
      "12                          Age Group_0-18    0.001298\n",
      "13                         Age Group_19-35    0.001216\n",
      "18                            Gender_Other    0.001096\n",
      "24  Availability of Vaccines/Treatment_Yes    0.000651\n",
      "19               Treatment Type_Medication    0.000000\n",
      "15                           Age Group_61+    0.000000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from scipy.stats import uniform\n",
    "import joblib\n",
    "\n",
    "# Load dataset\n",
    "file_path = \"/Users/rudradipkhanra/Downloads/Global Health Statistics.csv\"\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Define target and predictors\n",
    "target = \"Mortality Rate (%)\"\n",
    "predictors = [\n",
    "    \"Prevalence Rate (%)\",\n",
    "    \"Incidence Rate (%)\",\n",
    "    \"Age Group\",\n",
    "    \"Gender\",\n",
    "    \"Healthcare Access (%)\",\n",
    "    \"Doctors per 1000\",\n",
    "    \"Hospital Beds per 1000\",\n",
    "    \"Treatment Type\",\n",
    "    \"Average Treatment Cost (USD)\",\n",
    "    \"Availability of Vaccines/Treatment\",\n",
    "    \"Recovery Rate (%)\",\n",
    "    \"DALYs\",\n",
    "    \"Improvement in 5 Years (%)\",\n",
    "    \"Per Capita Income (USD)\",\n",
    "    \"Education Index\",\n",
    "    \"Urbanization Rate (%)\",\n",
    "]\n",
    "\n",
    "X = data[predictors]\n",
    "y = data[target]\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Preprocessing\n",
    "numerical_features = X.select_dtypes(include=[\"float64\", \"int64\"]).columns\n",
    "categorical_features = X.select_dtypes(include=[\"object\"]).columns\n",
    "\n",
    "numerical_transformer = StandardScaler()\n",
    "categorical_transformer = OneHotEncoder(handle_unknown=\"ignore\")\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numerical_transformer, numerical_features),\n",
    "        (\"cat\", categorical_transformer, categorical_features),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Model pipeline\n",
    "model_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"regressor\", GradientBoostingRegressor(random_state=42)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Distribution for RandomizedSearchCV\n",
    "param_dist = {\n",
    "    \"regressor__n_estimators\": [50, 100, 150],  # Optimized range\n",
    "    \"regressor__learning_rate\": uniform(0.05, 0.05),\n",
    "    \"regressor__max_depth\": [3, 5, 7],\n",
    "    \"regressor__subsample\": uniform(0.8, 0.2),\n",
    "}\n",
    "\n",
    "# Randomized search with cross-validation\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=model_pipeline,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=5,  # Reduce iterations to optimize runtime\n",
    "    cv=2,      # Use 2-fold cross-validation for large dataset\n",
    "    scoring=\"r2\",\n",
    "    n_jobs=-1,\n",
    "    verbose=2,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "# Fit the randomized search to the training data\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Best model\n",
    "best_model = random_search.best_estimator_\n",
    "\n",
    "# Save the trained model\n",
    "joblib.dump(best_model, \"mortality_rate_model.pkl\")\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = best_model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "print(f\"R-squared: {r2}\")\n",
    "\n",
    "# Feature importance\n",
    "regressor = best_model.named_steps[\"regressor\"]\n",
    "feature_importances = regressor.feature_importances_\n",
    "\n",
    "# Get the feature names after preprocessing\n",
    "preprocessed_feature_names = (\n",
    "    numerical_features.tolist()\n",
    "    + best_model.named_steps[\"preprocessor\"]\n",
    "    .transformers_[1][1]\n",
    "    .get_feature_names_out(categorical_features)\n",
    "    .tolist()\n",
    ")\n",
    "\n",
    "# Create a DataFrame for feature importances\n",
    "importance_df = pd.DataFrame({\n",
    "    \"Feature\": preprocessed_feature_names,\n",
    "    \"Importance\": feature_importances\n",
    "}).sort_values(by=\"Importance\", ascending=False)\n",
    "\n",
    "print(\"Feature Importances:\")\n",
    "print(importance_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "daee01af-c6ca-4020-9971-0270d9f58896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      " * Restarting with watchdog (fsevents)\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/ipykernel_launcher.py\", line 15, in <module>\n",
      "    from ipykernel import kernelapp as app\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/ipykernel/__init__.py\", line 7, in <module>\n",
      "    from .connect import *\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/ipykernel/connect.py\", line 12, in <module>\n",
      "    import jupyter_client\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/jupyter_client/__init__.py\", line 3, in <module>\n",
      "    from .asynchronous import AsyncKernelClient\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/jupyter_client/asynchronous/__init__.py\", line 1, in <module>\n",
      "    from .client import AsyncKernelClient  # noqa\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/jupyter_client/asynchronous/client.py\", line 11, in <module>\n",
      "    from ..channels import AsyncZMQSocketChannel, HBChannel\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/jupyter_client/channels.py\", line 12, in <module>\n",
      "    from jupyter_core.utils import ensure_async\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/jupyter_core/utils/__init__.py\", line 13, in <module>\n",
      "    from pathlib import Path\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/pathlib.py\", line 10, in <module>\n",
      "    from collections import Sequence\n",
      "ImportError: cannot import name 'Sequence' from 'collections' (/opt/anaconda3/lib/python3.11/collections/__init__.py)\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py:3561: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "import joblib\n",
    "import pandas as pd\n",
    "\n",
    "# Load the saved model\n",
    "model = joblib.load(\"mortality_rate_model.pkl\")\n",
    "\n",
    "# Initialize Flask app\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route(\"/\")\n",
    "def home():\n",
    "    return \"Welcome to the Mortality Rate Prediction API!\"\n",
    "\n",
    "@app.route(\"/predict\", methods=[\"POST\"])\n",
    "def predict():\n",
    "    try:\n",
    "        data = request.get_json()  # Expecting JSON input\n",
    "        df = pd.DataFrame(data)  # Convert JSON to DataFrame\n",
    "        predictions = model.predict(df)  # Model prediction\n",
    "        return jsonify({\"predictions\": predictions.tolist()})\n",
    "    except Exception as e:\n",
    "        return jsonify({\"error\": str(e)}), 400\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run(debug=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546390c0-9102-4498-82db-bfae14083675",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
